zhihu说明文档
==
介绍
 - 
zhihu是一个基于Scrapy的知乎话题内容爬虫，可以爬取知乎所有的话题相关的问答内容。由于知乎话题的问答内容信息巨大（亿级数据量），<br>
这里只是爬取了话题广场的“阅读”话题下的所有子话题下的精华问题与回答的相关信息。<br>

代码说明
--
### 运行环境
* Windows 10 专业版<br>
* Python 3.5/Scrapy 1.5.0/MongoDB 3.4.7<br>

### 依赖包
* Requests<br>
* Pymongo<br>
* Faker(随机切换User-Agent)<br>

### 其它
知乎话题广场有33个父话题，每个父话题有不同数量的子话题，每个子话题下又有很多的精华问题，每个精华问题下有不同数量的回答，如果想要完全爬取所有的问答，由于数据量太大，耗时太久。这里选择了“阅读”话题进行数据爬取。知乎的子话题、精华问答的内容都是采用动态加载的方法进行更新获取的，在分析了其动态加载链接后，从当前页面获取链接所需的参数并构造正确的链接，进行了三级深入的爬取。爬取过程中设置下载延迟为1S，知乎没有对这种低频率的访问做限制。

爬取结果
-
整个爬取过程持续了80个小时，总共获取了1140727条数据，结果存储在MongoDB中。再导出为Excle文件。部分数据如下截图:<br>
![股票信息截图](https://github.com/lanluyu/dongfang/blob/master/stocks.PNG)
